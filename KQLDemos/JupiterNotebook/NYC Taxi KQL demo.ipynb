{"cells":[{"cell_type":"markdown","source":["# NYC Taxi demo Notebooks and KQL. \r\n","This will use native python packages that are publicly available.\r\n","Goal: Query a publicly available dataset ([NYC taxi](https://learn.microsoft.com/en-us/azure/open-datasets/dataset-taxi-yellow?tabs=azureml-opendatasets)) and use a basic clustering ML model to detect where are the most busy taxi pickup hot spots in New York City. \r\n","\r\n","Note that as a prerequisite, your kusto database needs to have that data already ingested. Reach out to your buddy on how to ingest this.\r\n","\r\n","## High level notebook workflow\r\n","- Load up our dependencies using import commands\r\n","- Load up the [KQL magic](https://pypi.org/project/Kqlmagic/) package to allow connectivity to Kusto\r\n","- Authenticate to the Kusto database\r\n","- Demo a few KQL commands to showcase KQL interactivity through Jupyter notebook\r\n","- Train a model on a fraction of the data\r\n","- Display a graphical rendering for the clustering results on New York City taxi pickup location\r\n","\r\n","So let's start by loading up the numpi packages we need for the renders later..."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":["Then we load up some matplotlib packages for the graphs.."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import matplotlib\r\n","import matplotlib.pyplot as plt\r\n","%matplotlib inline"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Now it's time to import the KQL magic package wich will enable the kusto connectivity"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!pip install Kqlmagic --no-cache-dir --upgrade"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["we load up the package to memory"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["reload_ext Kqlmagic"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["And now we must connect to your cluster URL. You can get this in the kusto database landing page in the database detail section. "],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["This uses what is called Device Code authentication flow. It will give you a code that you need to input and then ask you to authenticate using your AAD credentials. Single sign on is difficult due to the notebook running on compute. It's much easier to use device auth flow but do know that some organizations will prevent this using AAD conditional access. Talk to your administrators if you run into authentication issue and ask us for help as well."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%kql kusto://code;cluster='https://qyqpv08152415261556787.westcentralus.kusto.windows.net';database='glhtrprpr'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["This step simply returns a count of the \"trips2\" table"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%kql trips2\r\n","| extend \r\n","  pickup_datetime= tpepPickupDateTime\r\n",", pickup_latitude = startLat\r\n",", pickup_longitude = startLon\r\n","| where pickup_datetime between (datetime(2014-01-01)..datetime(2014-12-31))\r\n","| where isnotempty(pickup_latitude) and isnotempty(pickup_longitude)\r\n","| count"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["This cells shows how the render commands is also available through KQL magic. Note that here it`s kusto doing the rendering, not python."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%kql      // Note the %% magic syntax to send full cell contents to ADX (including comment marker //)\r\n","trips2\r\n","| extend \r\n","  pickup_datetime= tpepPickupDateTime\r\n",", pickup_latitude = startLat\r\n",", pickup_longitude = startLon\r\n","| where pickup_datetime  between (datetime(2014-01-01)..datetime(2014-12-31))\r\n","| summarize count() by bin_at(pickup_datetime, 7d, datetime(2014-01-01))\r\n","| render timechart with(title='NYC 2014 Taxi Rides count per week')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Now we start working on a more detailed query that contextualizes the data using their geographic positions"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%kql trips2 \r\n","| extend \r\n","  pickup_datetime= tpepPickupDateTime\r\n",", dropoff_datetime = tpepDropoffDateTime\r\n",", pickup_latitude = startLat\r\n",", pickup_longitude = startLon\r\n",", dropoff_longitude = endLon\r\n",", dropoff_latitude = endLat\r\n",", vendor_id=vendorID\r\n","| where isnotempty(pickup_latitude) and isnotempty(pickup_longitude)\r\n","| project vendor_id, pickup_datetime, dropoff_datetime,pickup_longitude, pickup_latitude, dropoff_longitude,dropoff_latitude\r\n","| take 3"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Here we set some boundaries that will help us later"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Define NYC area limits\r\n","\r\n","south=40.61\r\n","north=40.91\r\n","west=-74.06\r\n","east=-73.77"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["1. Specify KQL query\r\n","2. Implement simple result cache in local binary (pickle) file, based on hash of the KQL query string\r\n","\r\n","NOTE: to make hash() consistent set env. variable PYTHONHASHSEED=0"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%env PYTHONHASHSEED=0\r\n","\r\n","def adx_query(q):\r\n","    fn = \"df\" + str(hash(q)) + \".pkl\"\r\n","    try:\r\n","        df = pd.read_pickle(fn)\r\n","        print(\"Load df from \" + fn)\r\n","        return df\r\n","    except:\r\n","        print(\"Execute query...\")\r\n","        %kql res << -query q\r\n","        try:\r\n","            df = res.to_dataframe()\r\n","            print(\"Save df to \" + fn)\r\n","            df.to_pickle(fn)\r\n","            print(\"\\n\", df.shape, \"\\n\", df.columns)\r\n","            return df\r\n","        except Exception as ex:\r\n","            print(ex)\r\n","            return None"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["the \"Q\" variable holds our main KQL code. This will aggregate all pickups within our geographic boundary. "],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["q = '''\r\n","set notruncation;\r\n","let South=south; let North=north; let West=west; let East=east; // copy Python variables to ADX\r\n","trips2\r\n","| extend \r\n","  pickup_datetime= tpepPickupDateTime\r\n",", dropoff_datetime = tpepDropoffDateTime\r\n",", pickup_latitude = startLat\r\n",", pickup_longitude = startLon\r\n",", dropoff_longitude = endLon\r\n",", dropoff_latitude = endLat\r\n",", vendor_id=vendorID\r\n","| where pickup_datetime between (datetime(2014-01-01)..datetime(2014-12-31))\r\n","| where isnotempty(pickup_latitude) and isnotempty(pickup_longitude)\r\n","| extend Lat=round(pickup_latitude, 4), Long=round(pickup_longitude, 4)\r\n","| where Lat between(South..North) and Long between(West..East)\r\n","| summarize num_pickups=count() by Lat, Long\r\n","'''\r\n","\r\n","aggr_pickups = adx_query(q)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["we show 4 rows of the dataframe..."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["print(aggr_pickups[-4:])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Initialize graphics for heatmap"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["new_style = {'grid':False}\r\n","matplotlib.rc('axes', **new_style)\r\n","from matplotlib import rcParams\r\n","rcParams['figure.figsize'] = [15, 15]"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["We draw a map by ploting a heat map over a scatter plot. Does this look familiar?"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["plt.style.use('dark_background')\r\n","p = aggr_pickups.plot(kind='scatter', x='Long', y='Lat', color='white', xlim=(west, east), ylim=(south, north), s=0.02, alpha=0.6)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":[" We grab a small subset of the data for training 0.1%"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["q = '''\r\n","set notruncation;\r\n","let South=south; let North=north; let West=west; let East=east; // copy Python variables to ADX\r\n","let sf=0.001; // Extract 0.1% of the raw data\r\n","trips2\r\n","| extend \r\n","  pickup_datetime= tpepPickupDateTime\r\n",", dropoff_datetime = tpepDropoffDateTime\r\n",", pickup_latitude = startLat\r\n",", pickup_longitude = startLon\r\n",", dropoff_longitude = endLon\r\n",", dropoff_latitude = endLat\r\n",", vendor_id=vendorID\r\n","| where pickup_datetime between (datetime(2014-01-01)..datetime(2014-12-31))\r\n","| where pickup_latitude between(South..North) and pickup_longitude between(West..East)\r\n","| project pickup_datetime, pickup_latitude, pickup_longitude\r\n","| where rand() < sf'''\r\n","\r\n","df = adx_query(q)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["We define the clustering function"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["def KMeans_clustering(k, features):\r\n","    from sklearn.cluster import KMeans, MiniBatchKMeans\r\n","    km = MiniBatchKMeans(n_clusters=k) if features.shape[0] > 1000 else KMeans(n_clusters=k)\r\n","    km.fit(features)\r\n","    centroids = pd.DataFrame(km.cluster_centers_, columns=features.columns)\r\n","    centroids.insert(features.shape[1], \"num\", pd.DataFrame(km.labels_, columns=[\"n\"]).groupby(\"n\").size())\r\n","    centroids.insert(features.shape[1], \"cluster_id\", range(k))\r\n","    return centroids, km.labels_"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["We define a few more variables and mark the centroids on the map with stars"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["pickup_hub_loc, pickup_cluster = KMeans_clustering(8, df[['pickup_latitude', 'pickup_longitude']])\r\n","pickup_hub_loc"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["plt.scatter(x=aggr_pickups['Long'], y=aggr_pickups['Lat'], color='white', s=0.02, alpha=0.6)\r\n","plt.scatter(x=pickup_hub_loc['pickup_longitude'], y=pickup_hub_loc['pickup_latitude'], color='#ff00a0', marker='*', s=pickup_hub_loc['num']/len(df)*8000, alpha=0.6)\r\n","plt.show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"description":"","save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"keepAliveTimeout":30,"enableDebugMode":false,"conf":{"spark.livy.synapse.ipythonInterpreter.enabled":"true"}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":0}